{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smallNORB Experiments.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR2OJ0eL-5Oh",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Dataset\n",
        "\n",
        "Download and prepare dataset for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjzBjnQ7-uTh",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "230d3878-768b-4719-fadc-509d26520194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Download Dataset\n",
        "!rm -r *\n",
        "!wget https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x46789x9x18x6x2x96x96-training-dat.mat.gz\n",
        "!wget https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x46789x9x18x6x2x96x96-training-cat.mat.gz\n",
        "!wget https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x46789x9x18x6x2x96x96-training-info.mat.gz\n",
        "!wget https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat.gz\n",
        "!wget https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x01235x9x18x6x2x96x96-testing-cat.mat.gz\n",
        "!wget https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x01235x9x18x6x2x96x96-testing-info.mat.gz\n",
        "\n",
        "!mkdir dataset\n",
        "!mv *.gz dataset/\n",
        "!gunzip dataset/*.gz\n",
        "!rm dataset/*.gz\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-12 07:52:26--  https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x46789x9x18x6x2x96x96-training-dat.mat.gz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131896188 (126M) [application/x-gzip]\n",
            "Saving to: ‘smallnorb-5x46789x9x18x6x2x96x96-training-dat.mat.gz’\n",
            "\n",
            "smallnorb-5x46789x9 100%[===================>] 125.79M  14.8MB/s    in 10s     \n",
            "\n",
            "2019-07-12 07:52:37 (12.0 MB/s) - ‘smallnorb-5x46789x9x18x6x2x96x96-training-dat.mat.gz’ saved [131896188/131896188]\n",
            "\n",
            "--2019-07-12 07:52:40--  https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x46789x9x18x6x2x96x96-training-cat.mat.gz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 348 [application/x-gzip]\n",
            "Saving to: ‘smallnorb-5x46789x9x18x6x2x96x96-training-cat.mat.gz’\n",
            "\n",
            "smallnorb-5x46789x9 100%[===================>]     348  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-12 07:52:40 (68.8 MB/s) - ‘smallnorb-5x46789x9x18x6x2x96x96-training-cat.mat.gz’ saved [348/348]\n",
            "\n",
            "--2019-07-12 07:52:43--  https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x46789x9x18x6x2x96x96-training-info.mat.gz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71052 (69K) [application/x-gzip]\n",
            "Saving to: ‘smallnorb-5x46789x9x18x6x2x96x96-training-info.mat.gz’\n",
            "\n",
            "smallnorb-5x46789x9 100%[===================>]  69.39K   177KB/s    in 0.4s    \n",
            "\n",
            "2019-07-12 07:52:44 (177 KB/s) - ‘smallnorb-5x46789x9x18x6x2x96x96-training-info.mat.gz’ saved [71052/71052]\n",
            "\n",
            "--2019-07-12 07:52:46--  https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat.gz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130799817 (125M) [application/x-gzip]\n",
            "Saving to: ‘smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat.gz’\n",
            "\n",
            "smallnorb-5x01235x9 100%[===================>] 124.74M  15.1MB/s    in 9.7s    \n",
            "\n",
            "2019-07-12 07:52:57 (12.9 MB/s) - ‘smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat.gz’ saved [130799817/130799817]\n",
            "\n",
            "--2019-07-12 07:52:58--  https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x01235x9x18x6x2x96x96-testing-cat.mat.gz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347 [application/x-gzip]\n",
            "Saving to: ‘smallnorb-5x01235x9x18x6x2x96x96-testing-cat.mat.gz’\n",
            "\n",
            "smallnorb-5x01235x9 100%[===================>]     347  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-12 07:52:59 (60.3 MB/s) - ‘smallnorb-5x01235x9x18x6x2x96x96-testing-cat.mat.gz’ saved [347/347]\n",
            "\n",
            "--2019-07-12 07:53:01--  https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x01235x9x18x6x2x96x96-testing-info.mat.gz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10428 (10K) [application/x-gzip]\n",
            "Saving to: ‘smallnorb-5x01235x9x18x6x2x96x96-testing-info.mat.gz’\n",
            "\n",
            "smallnorb-5x01235x9 100%[===================>]  10.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-12 07:53:02 (177 MB/s) - ‘smallnorb-5x01235x9x18x6x2x96x96-testing-info.mat.gz’ saved [10428/10428]\n",
            "\n",
            "rm: cannot remove 'dataset/*.gz': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgcCYPXW_InN",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "d6e00f11-905e-4b91-b7a5-34a2bd52412e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#@title Download Dataset Parser\n",
        "!git clone https://github.com/ndrplz/small_norb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'small_norb'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Total 79 (delta 0), reused 0 (delta 0), pack-reused 79\u001b[K\n",
            "Unpacking objects: 100% (79/79), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTvXINs3_pvI",
        "colab_type": "code",
        "outputId": "73d46be3-b118-43ba-f536-8756e1fe1a52",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#@title Initialize Dataset Parser\n",
        "\n",
        "from small_norb.smallnorb.dataset import SmallNORBDataset\n",
        "\n",
        "dataset = SmallNORBDataset(dataset_root='dataset')\n",
        "categories = ['animal', 'human', 'airplane', 'truck', 'car']"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading images...: 100%|██████████| 48600/48600 [00:38<00:00, 1273.37it/s]\n",
            "Loading categories...: 100%|██████████| 24300/24300 [00:00<00:00, 1027829.08it/s]\n",
            "Loading info...: 100%|██████████| 24300/24300 [00:00<00:00, 307303.74it/s]\n",
            "Loading images...: 100%|██████████| 48600/48600 [00:37<00:00, 1294.36it/s]\n",
            "Loading categories...: 100%|██████████| 24300/24300 [00:00<00:00, 1016684.33it/s]\n",
            "Loading info...: 100%|██████████| 24300/24300 [00:00<00:00, 315320.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW7MWz6GeECJ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Data Preprocessing Functions\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def split(dataset, conf):\n",
        "  random.shuffle(dataset)\n",
        "  \n",
        "  # class based sets\n",
        "  train_set = [ [] for i in range(len(categories)) ]\n",
        "  val_set = [ [] for i in range(len(categories)) ]\n",
        "  test_set = [ [] for i in range(len(categories)) ]\n",
        "  \n",
        "  for toy_set in dataset:\n",
        "    cat = toy_set[0].category\n",
        "    if len(val_set[cat]) < conf['val']:\n",
        "      val_set[cat].append(toy_set)\n",
        "    elif len(test_set[cat]) < conf['test']:\n",
        "      test_set[cat].append(toy_set)\n",
        "    else:\n",
        "      train_set[cat].append(toy_set)\n",
        "      \n",
        "      \n",
        "  train_set  = [toy_set for cat in train_set for toy_set in cat]\n",
        "  val_set  = [toy_set for cat in val_set for toy_set in cat]\n",
        "  test_set  = [toy_set for cat in test_set for toy_set in cat]\n",
        "  return train_set, val_set, test_set\n",
        "\n",
        "def filter(dataset, conf):\n",
        "  x_values, y_values = [], []\n",
        "  for toy_set in dataset:\n",
        "    for sample in toy_set:\n",
        "      if sample.elevation not in conf['elevation']:\n",
        "        continue\n",
        "      if sample.azimuth not in conf['azimuth']:\n",
        "        continue\n",
        "      if sample.lighting not in conf['lighting']:\n",
        "        continue\n",
        "        \n",
        "      if sample.category in conf['categories']:\n",
        "        if sample.elevation not in conf.categories[sample.category]['elevation']:\n",
        "          continue\n",
        "        if sample.azimuth not in conf.categories[sample.category]['azimuth']:\n",
        "          continue\n",
        "        if sample.lighting not in conf.categories[sample.category]['lighting']:\n",
        "          continue\n",
        "      x_values.append( np.expand_dims(sample.image_lt, axis=-1) )\n",
        "      y_values.append( to_categorical(sample.category, len(categories) ) )\n",
        "  return np.asarray(x_values), np.asarray(y_values)\n",
        "\n",
        "def process(conf):\n",
        "  # Get original test and train sets\n",
        "  test_set = dataset.group_dataset_by_category_and_instance('test')\n",
        "  train_set = dataset.group_dataset_by_category_and_instance('train')\n",
        "\n",
        "  # Split dataset into train/val/test\n",
        "  train_set, val_set, test_set = split( test_set + train_set, conf['split'] )\n",
        "\n",
        "  # Preprocess datasets to match our configurations\n",
        "  train_x, train_y = filter(train_set, conf['train'])\n",
        "  val_x, val_y = filter(val_set, conf['train'])\n",
        "  test_x, test_y = filter(test_set, conf['test'])\n",
        "  \n",
        "  return (train_x, train_y), (val_x, val_y), (test_x, test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-OQ5_N5RYWs",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAHHpm0MqvNP",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title LocalNormalization Definition\n",
        "from keras.engine import Layer, InputSpec\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Add, Dense,Dropout, Lambda\n",
        "\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "\n",
        "class LocalNormalization(Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 groupsize=32,\n",
        "                 axis=0,\n",
        "                 epsilon=1e-5,\n",
        "                 center=True,\n",
        "                 scale=True,\n",
        "                 beta_initializer='zeros',\n",
        "                 gamma_initializer='ones',\n",
        "                 beta_regularizer=None,\n",
        "                 gamma_regularizer=None,\n",
        "                 beta_constraint=None,\n",
        "                 gamma_constraint=None,\n",
        "                 batch_size = 100,\n",
        "                 **kwargs):\n",
        "        super(LocalNormalization, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.groups = groupsize\n",
        "        self.batch_size = batch_size\n",
        "        self.axis = axis\n",
        "        self.epsilon = epsilon\n",
        "        self.center = center\n",
        "        self.scale = scale\n",
        "        self.beta_initializer = initializers.get(beta_initializer)\n",
        "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
        "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
        "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
        "        self.beta_constraint = constraints.get(beta_constraint)\n",
        "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dim = input_shape[self.axis]\n",
        "        \n",
        "        if dim is None:\n",
        "            dim = self.batch_size\n",
        "\n",
        "        if dim < self.groups:\n",
        "            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n",
        "                             'more than the batch size (' +\n",
        "                             str(dim) + ').')\n",
        "\n",
        "        if dim % self.groups != 0:\n",
        "            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n",
        "                             'multiple of the batch size (' +\n",
        "                             str(dim) + ').')\n",
        "\n",
        "        self.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
        "        shape = (dim//self.groups,input_shape[-1])\n",
        "\n",
        "        if self.scale:\n",
        "            self.gamma = self.add_weight(shape=shape,\n",
        "                                         name='gamma',\n",
        "                                         initializer=self.gamma_initializer,\n",
        "                                         regularizer=self.gamma_regularizer,\n",
        "                                         constraint=self.gamma_constraint)\n",
        "        else:\n",
        "            self.gamma = None\n",
        "        if self.center:\n",
        "            self.beta = self.add_weight(shape=shape,\n",
        "                                        name='beta',\n",
        "                                        initializer=self.beta_initializer,\n",
        "                                        regularizer=self.beta_regularizer,\n",
        "                                        constraint=self.beta_constraint)\n",
        "        else:\n",
        "            self.beta = None\n",
        "       \n",
        "        \n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        input_shape = K.int_shape(inputs)\n",
        "        tensor_input_shape = K.shape(inputs)\n",
        "\n",
        "        # Prepare broadcasting shape.\n",
        "        reduction_axes = list(range(len(input_shape)))\n",
        "        del reduction_axes[self.axis]\n",
        "        \n",
        "        div = lambda x:x//self.groups\n",
        "        \n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        broadcast_shape[self.axis] = div(self.batch_size)\n",
        "        broadcast_shape[-1] = input_shape[-1]\n",
        "        broadcast_shape.insert(1, 1)\n",
        "\n",
        "        reshape_group_shape = K.int_shape(inputs)\n",
        "        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
        "        group_axes[self.axis] = div(self.batch_size)\n",
        "        group_axes.insert(1, self.groups)\n",
        "        \n",
        "\n",
        "        # reshape inputs to new group shape\n",
        "        group_shape = [group_axes[0], self.groups]+group_axes[2:]\n",
        "        group_shape = K.stack(group_shape)\n",
        "        \n",
        "        inputs = K.reshape(inputs, group_shape)\n",
        "        \n",
        "        group_reduction_axes = list(range(len(group_axes)))\n",
        "        group_reduction_axes = [1,2,3]\n",
        "\n",
        "        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
        "        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
        "\n",
        "        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
        "\n",
        "        # prepare broadcast shape\n",
        "        inputs = K.reshape(inputs, group_shape)\n",
        "        \n",
        "        outputs = inputs\n",
        "        \n",
        "        # In this case we must explicitly broadcast all parameters.\n",
        "        if self.scale:           \n",
        "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
        "            outputs = outputs * broadcast_gamma\n",
        "            \n",
        "        if self.center:\n",
        "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
        "            outputs = outputs + broadcast_beta\n",
        "        outputs = K.reshape(outputs, tensor_input_shape)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'groups': self.groups,\n",
        "            'axis': self.axis,\n",
        "            'epsilon': self.epsilon,\n",
        "            'center': self.center,\n",
        "            'scale': self.scale,\n",
        "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
        "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
        "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
        "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
        "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
        "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
        "        }\n",
        "        base_config = super(LocalNormalization, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFN-kljne4EB",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title VGG Model Definition\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Activation, Flatten, Dense, MaxPooling2D, BatchNormalization, Dropout\n",
        "from keras.regularizers import l2\n",
        "\n",
        "def norm(norm_type, batch_size=None, groupsize=None):\n",
        "  if norm_type=='batch':\n",
        "    return BatchNormalization()\n",
        "  elif norm_type=='local':\n",
        "    return LocalNormalization(axis=0, batch_size=batch_size, groupsize=groupsize)\n",
        "  return None\n",
        "\n",
        "def build_model(name='vgg', input_shape=(96,96,1,), input_layer=None, nb_classes=5, weight_decay=0.0005, norm_type='batch', batch_size=128, group_size=8):  \n",
        "  if input_layer is None:\n",
        "    inputs = Input(shape=input_shape)\n",
        "  else:\n",
        "    inputs = input_layer\n",
        "  x = inputs\n",
        "  \n",
        "  x = Conv2D(64, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = Conv2D(64, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "  x = Conv2D(128, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = Conv2D(128, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "  x = Conv2D(256, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = Conv2D(256, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = Conv2D(256, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "\n",
        "  x = Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "\n",
        "  x = Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = norm(norm_type, batch_size=batch_size, groupsize=group_size)(x)\n",
        "\n",
        "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(512,kernel_regularizer=l2(weight_decay))(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(nb_classes)(x)\n",
        "  x = Activation('softmax', name=name+'_output')(x)\n",
        "  \n",
        "  outputs = x\n",
        "  return Model(name=name, inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UCL70SSJ0bs",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZZvr3lvRHqo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Configure Models\n",
        "\n",
        "nb_classes = 5\n",
        "image_height = 96\n",
        "image_width = 96\n",
        "input_shape = (image_height, image_width, 1)\n",
        "batch_size = 128\n",
        "group_size = 4\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "model_batch = build_model(name='batch_vgg', input_layer=inputs, norm_type='batch', batch_size=batch_size, group_size=group_size, nb_classes=nb_classes)\n",
        "model_local = build_model(name='local_vgg', input_layer=inputs, norm_type='local', batch_size=batch_size, group_size=group_size, nb_classes=nb_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9yZ_LrjRaVC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Optional) Load Weights\n",
        "\n",
        "#model_batch.load_weights('weights-batch.h5')\n",
        "#model_local.load_weights('weights-local.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymo7tnnF892J",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "f2eb9e97-75e5-455c-d788-4fcde932383f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "#@title (Deprecated) Combine Models\n",
        "\n",
        "'''\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "losses = {\n",
        "\tmodel_batch.layers[-1].name: 'categorical_crossentropy',\n",
        "\tmodel_local.layers[-1].name: 'categorical_crossentropy',\n",
        "}\n",
        "\n",
        "model = Model(name='vgg', inputs=inputs, outputs=[model_batch.output, model_local.output])\n",
        "model.compile(loss=losses, optimizer=SGD(lr=0.1, momentum=0.9), metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "'''"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom keras.optimizers import SGD\\n\\nlosses = {\\n\\tmodel_batch.layers[-1].name: 'categorical_crossentropy',\\n\\tmodel_local.layers[-1].name: 'categorical_crossentropy',\\n}\\n\\nmodel = Model(name='vgg', inputs=inputs, outputs=[model_batch.output, model_local.output])\\nmodel.compile(loss=losses, optimizer=SGD(lr=0.1, momentum=0.9), metrics=['accuracy'])\\n\\nmodel.summary()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eT_idAw1_gY",
        "colab_type": "text"
      },
      "source": [
        "# Train Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiYNTb9o_9zR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Configure Dataset\n",
        "\n",
        "import random\n",
        "\n",
        "# TODO: Add camera options to configuration\n",
        "train_data_conf = {\n",
        "    'elevation': list(range(9)),\n",
        "    'azimuth': list(range(18)),\n",
        "    'lighting': [0,1,2,3], #list(range(6))\n",
        "    'categories': {}\n",
        "}\n",
        "test_data_conf = {\n",
        "    'elevation': list(range(9)),\n",
        "    'azimuth': list(range(18)),\n",
        "    'lighting': list(range(6)),\n",
        "    'categories': {}\n",
        "}\n",
        "data_conf = {\n",
        "    'train': train_data_conf,\n",
        "    'test': test_data_conf,\n",
        "    'split': {\n",
        "        'train': 8,\n",
        "        'val': 1,\n",
        "        'test': 1\n",
        "    }\n",
        "}\n",
        "\n",
        "(train_x, train_y), (val_x, val_y), (test_x, test_y) = process(data_conf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSYCOgn8-Xs2",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Trim Dataset\n",
        "\n",
        "# trim dataset according to batch_size for LocalNorm to work properly\n",
        "\n",
        "train_x = train_x[:((len(train_x) // batch_size) * batch_size)]\n",
        "train_y = train_y[:((len(train_y) // batch_size) * batch_size)]\n",
        "val_x = val_x[:((len(val_x) // batch_size) * batch_size)]\n",
        "val_y = val_y[:((len(val_y) // batch_size) * batch_size)]\n",
        "test_x = test_x[:((len(test_x) // batch_size) * batch_size)]\n",
        "test_y = test_y[:((len(test_y) // batch_size) * batch_size)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXDXiqiGCGT0",
        "colab_type": "code",
        "outputId": "90d82ba8-cbaa-4eb8-89dc-3ff9c2392395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "cellView": "form"
      },
      "source": [
        "#@title Inspect Dataset\n",
        "\n",
        "print('Input Shape:')\n",
        "print(train_x.shape[1:])\n",
        "\n",
        "print('Train Dataset Size:')\n",
        "print(train_x.shape[0])\n",
        "\n",
        "print('Val Dataset Size:')\n",
        "print(val_x.shape[0])\n",
        "\n",
        "print('Test Dataset Size:')\n",
        "print(test_x.shape[0])\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index = np.random.randint(len(train_x))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(train_x[index][:,:,0], cmap='gray')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Shape:\n",
            "(96, 96, 1)\n",
            "Train Dataset Size:\n",
            "12928\n",
            "Val Dataset Size:\n",
            "1536\n",
            "Test Dataset Size:\n",
            "2304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7a0eca61d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL0AAAC7CAYAAAAwjp8tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndwhCH5A7/H9SsLY2BdjXsAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4wdnRKp2kbb",
        "colab_type": "code",
        "outputId": "9af0c674-29bf-4a8a-e258-7643d5323f1e",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Train & Monitor\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "initial_epoch = 0\n",
        "final_epoch = 100\n",
        "learning_rate = 1e-5\n",
        "drop_freq_epoch = 10\n",
        "drop_rate = 0.1\n",
        "\n",
        "# Checkpoints\n",
        "checkpoint_batch = ModelCheckpoint('weights-batch.h5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "checkpoint_local = ModelCheckpoint('weights-local.h5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "# Early Stopping\n",
        "early_batch = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "early_local = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "# Learning Rate Regularizer\n",
        "def lr_scheduler(epoch):\n",
        "  return learning_rate * (drop_rate ** (epoch // drop_freq_epoch))\n",
        "\n",
        "lr_regularizer_batch = LearningRateScheduler(lr_scheduler)\n",
        "lr_regularizer_local = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_batch = SGD(lr=learning_rate, momentum=0.9)\n",
        "optimizer_local = SGD(lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# Compile\n",
        "model_batch.compile(loss='categorical_crossentropy', optimizer=optimizer_batch, metrics=['accuracy'])\n",
        "model_local.compile(loss='categorical_crossentropy', optimizer=optimizer_local, metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "hist_batch = model_batch.fit(x=train_x, y=train_y, batch_size=batch_size, initial_epoch=initial_epoch, epochs=final_epoch, validation_data=(val_x, val_y), callbacks=[checkpoint_batch, early_batch, lr_regularizer_batch])\n",
        "hist_local = model_local.fit(x=train_x, y=train_y, batch_size=batch_size, initial_epoch=initial_epoch, epochs=final_epoch, validation_data=(val_x, val_y), callbacks=[checkpoint_local, early_local, lr_regularizer_local])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 12928 samples, validate on 1536 samples\n",
            "Epoch 1/100\n",
            "12928/12928 [==============================] - 92s 7ms/step - loss: 6.1152 - acc: 0.2554 - val_loss: 4.3044 - val_acc: 0.3197\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.31966, saving model to weights-batch.h5\n",
            "Epoch 2/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 5.0263 - acc: 0.3640 - val_loss: 3.9830 - val_acc: 0.4069\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.31966 to 0.40690, saving model to weights-batch.h5\n",
            "Epoch 3/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 4.4995 - acc: 0.4394 - val_loss: 3.6423 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.40690 to 0.51432, saving model to weights-batch.h5\n",
            "Epoch 4/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 4.2379 - acc: 0.4745 - val_loss: 4.4435 - val_acc: 0.2747\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.51432\n",
            "Epoch 5/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 4.0244 - acc: 0.5248 - val_loss: 4.0644 - val_acc: 0.3945\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.51432\n",
            "Epoch 6/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.8203 - acc: 0.5658 - val_loss: 3.9290 - val_acc: 0.4655\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.51432\n",
            "Epoch 7/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.6472 - acc: 0.6031 - val_loss: 3.2908 - val_acc: 0.6374\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.51432 to 0.63737, saving model to weights-batch.h5\n",
            "Epoch 8/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.5080 - acc: 0.6449 - val_loss: 3.3257 - val_acc: 0.6322\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.63737\n",
            "Epoch 9/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.4288 - acc: 0.6662 - val_loss: 3.2186 - val_acc: 0.6921\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.63737 to 0.69206, saving model to weights-batch.h5\n",
            "Epoch 10/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.3323 - acc: 0.6891 - val_loss: 3.5211 - val_acc: 0.5736\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.69206\n",
            "Epoch 11/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.2675 - acc: 0.7112 - val_loss: 3.0101 - val_acc: 0.7858\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.69206 to 0.78581, saving model to weights-batch.h5\n",
            "Epoch 12/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.2348 - acc: 0.7205 - val_loss: 2.8532 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.78581 to 0.83854, saving model to weights-batch.h5\n",
            "Epoch 13/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.2320 - acc: 0.7259 - val_loss: 2.8348 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.83854 to 0.84375, saving model to weights-batch.h5\n",
            "Epoch 14/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.2141 - acc: 0.7225 - val_loss: 2.8186 - val_acc: 0.8555\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.84375 to 0.85547, saving model to weights-batch.h5\n",
            "Epoch 15/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.2089 - acc: 0.7322 - val_loss: 2.8107 - val_acc: 0.8665\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.85547 to 0.86654, saving model to weights-batch.h5\n",
            "Epoch 16/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.1855 - acc: 0.7350 - val_loss: 2.8155 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.86654\n",
            "Epoch 17/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.1739 - acc: 0.7406 - val_loss: 2.8110 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.86654\n",
            "Epoch 18/100\n",
            "12928/12928 [==============================] - 86s 7ms/step - loss: 3.1793 - acc: 0.7393 - val_loss: 2.8014 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.86654\n",
            "Epoch 19/100\n",
            " 3072/12928 [======>.......................] - ETA: 1:02 - loss: 3.1847 - acc: 0.7314"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BNMWytKP_Ow",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title Evaluate Models\n",
        "results_batch = model_batch.evaluate(x=text_x, y=novel_test_y, batch_size=batch_size)\n",
        "results_local = model_local.evaluate(x=test_x, y=novel_test_y, batch_size=batch_size)\n",
        "\n",
        "print('BatchNorm Test Accuracy:')\n",
        "print(results_batch[1])\n",
        "\n",
        "print('LocalNorm Test Accuracy:')\n",
        "print(results_local[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hsjwfS0LHtX",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title Save Training \n",
        "\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "def save_training():\n",
        "  train_conf = {\n",
        "      'learning_rate': learning_rate,\n",
        "      'drop_freq_epoch': drop_freq_epoch,\n",
        "      'drop_rate': drop_rate\n",
        "  }\n",
        "  result_batch = {\n",
        "      'history': hist_batch.history,\n",
        "      'results': {\n",
        "          'test': results_batch\n",
        "  }\n",
        "  result_local = {\n",
        "      'history': hist_local.history,\n",
        "      'results': {\n",
        "          'test': results_local\n",
        "      }\n",
        "  }\n",
        "  \n",
        "  with open('data.json', 'w') as f:\n",
        "      json.dump(data_conf, f)\n",
        "  with open('train.json', 'w') as f:\n",
        "      json.dump(train_conf, f)\n",
        "\n",
        "  with open('result-batch.json', 'w') as f:\n",
        "      json.dumps(result_batch)\n",
        "  with open('result-local.json', 'w') as f:\n",
        "      json.dumps(result_local)\n",
        "      \n",
        "  with open('model-batch.json', 'w') as f:\n",
        "      f.write(model_batch.to_json())\n",
        "  with open('model-local.json', 'w') as f:\n",
        "      f.write(model_local.to_json())\n",
        "\n",
        "    \n",
        "def download_training():\n",
        "  files.download('data.json') \n",
        "  files.download('train.json') \n",
        "  files.download('model-batch.json') \n",
        "  files.download('model-local.json') \n",
        "  files.download('result-batch.json') \n",
        "  files.download('result-local.json') \n",
        "  files.download('weights-batch.json') \n",
        "  files.download('weights-local.json') \n",
        "\n",
        "save_training()\n",
        "download_training()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAK-oPZqM38e",
        "colab_type": "text"
      },
      "source": [
        "# Test Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_6XNrOotjRm",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot Helper\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot(metrics, legend=['train', 'test'], title='Model Accuracy', xlabel='epoch', ylabel='accuracy'):\n",
        "  for metric in metrics:\n",
        "    plt.plot(metric)\n",
        "  plt.title(title)\n",
        "  plt.ylabel(xlabel)\n",
        "  plt.xlabel(ylabel)\n",
        "  plt.legend(legend, loc='lower right')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4DXmKU8WxFk",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title Load Training\n",
        "\n",
        "from keras.models import model_from_json\n",
        "\n",
        "def load_training():\n",
        "  with open('train.json') as f:\n",
        "      train_conf = json.load(f)\n",
        "  with open('data.json') as f:\n",
        "      data_conf = json.load(f)\n",
        "  \n",
        "  with open('model-batch.json', 'r') as f:\n",
        "      model_batch = model_from_json(f.read())\n",
        "      model_batch.load_weights('weights-batch.json')\n",
        "  with open('model-local.json', 'r') as f:\n",
        "      model_local = model_from_json(f.read())\n",
        "      model_local.load_weights('weights-local.json')\n",
        "      \n",
        "  with open('result-batch.json') as f:\n",
        "      result_batch = json.load(f)\n",
        "  with open('result-local.json') as f:\n",
        "      result_local = json.load(f)\n",
        "      \n",
        "  return ( data_conf, train_conf, [ model_batch, model_local ], [ result_batch, result_local ] )\n",
        "\n",
        "training_results = load_training()\n",
        "data_conf = training_results[0]\n",
        "train_conf = training_results[1]\n",
        "model_batch = training_results[2][0]\n",
        "model_local = training_results[2][1]\n",
        "result_batch = training_results[3][0]\n",
        "result_local = training_results[3][1]\n",
        "\n",
        "process(data_conf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGYnlQN6A80w",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lIP7CWg4Szy",
        "colab_type": "text"
      },
      "source": [
        "### Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmx02zsUM_dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "legend = [ 'batch', 'local']\n",
        "metrics = [ result_batch['history']['val_acc'], result_local['history']['val_acc'] ]\n",
        "plot(metrics, legend=legend, title='BatchNorm vs LocalNorm Model Accuracy', xlabel='epoch', ylabel='accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JogfUy4stGTx",
        "colab_type": "text"
      },
      "source": [
        "### Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wujOVr6_O2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('BatchNorm Test Accuracy:')\n",
        "print(result_batch['test'][1])\n",
        "\n",
        "print('LocalNorm Test Accuracy:')\n",
        "print(result_local['test'][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og3r7y6WCIUa",
        "colab_type": "text"
      },
      "source": [
        "### Experiment Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0FYn2Q0CUfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train Configurations:')\n",
        "print(train_conf)\n",
        "\n",
        "print('Test Configurations:')\n",
        "print(test_conf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS9yyYpb9na9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment_conf = {\n",
        "    'elevation': list(range(6)),\n",
        "    'azimuth': list(range(18)),\n",
        "    'lighting': list(range(6)),\n",
        "    'categories': {}\n",
        "}\n",
        "\n",
        "def experiment(name, experiment_conf):\n",
        "  experiment_x, experiment_y = preprocess(test_set, novel_test_conf)\n",
        "  experiment_x = experiment_x[:((len(experiment_x) // batch_size) * batch_size)]\n",
        "  experiment_y = experiment_y[:((len(experiment_y) // batch_size) * batch_size)]\n",
        "  \n",
        "  experiment_batch = model_batch.evaluate(x=novel_test_x, y=novel_test_y, batch_size=batch_size)\n",
        "  experiment_local = model_local.evaluate(x=novel_test_x, y=novel_test_y, batch_size=batch_size)\n",
        "\n",
        "  print('BatchNorm Experiment Accuracy:')\n",
        "  print(experiment_batch[1])\n",
        "\n",
        "  print('LocalNorm Experiment Accuracy:')\n",
        "  print(experiment_local[1])\n",
        "  \n",
        "  data_conf[name] = experiment_conf\n",
        "  result_batch[name] = experiment_batch\n",
        "  result_local[name] = experiment_local\n",
        "\n",
        "  with open('data.json', 'w') as f:\n",
        "      json.dump(data_conf, f)\n",
        "  with open('result-batch.json', 'w') as f:\n",
        "      json.dumps(result_batch)\n",
        "  with open('result-local.json', 'w') as f:\n",
        "      json.dumps(result_local)\n",
        "  \n",
        "experiment('novel-lighting', experiment_conf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThNHkrE7Ozl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}